{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditionnal Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let $N$ be an integer, and consider the probability vector $p = (p_1, p_2, \\dots, p_N)$ where each $p_i$ belongs to the interval $(0,1)$ for  $i = 1, \\dots, N$.  \n",
    "The sample space is given by $\\Omega = \\{0,1\\}^N.$  \n",
    "We assume that $I$ is an integer satisfying $I \\leq \\frac{N}{2}$.  \n",
    "Let $g$ be the probability density function of the random vector  \n",
    "$$\n",
    "(X_1, \\dots, X_N)\n",
    "$$\n",
    "where the $X_i$ are independent Bernoulli random variables $X_i \\sim \\mathsf{B}(p_i).$  \n",
    "Finally, let $f$ be the probability density function of  \n",
    "$$\n",
    "(X_1, \\dots, X_N) \\sim \\mathsf{CB}(p, I).\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the following proposition from the lecture :\n",
    "> Let $f$, $g$ be probability density functions (PDFs) such that the support of $g$ contains the support of $f$ and\n",
    "> \n",
    "> $$\n",
    "> f \\leq M g \\quad \\text{with } M \\geq 1.\n",
    "> $$\n",
    "> \n",
    "> ### Accept-Reject Algorithm\n",
    "> Repeat:  \n",
    "> 1. Draw $X \\sim g$ and $U \\sim U[0,1]$.  \n",
    "> 2. Until $U \\leq \\frac{f(X)}{M g(X)}$.\n",
    "> \n",
    "> ### Properties:\n",
    "> - $X \\sim f$ \n",
    "> - The number of draws until acceptance follows a **Geometric** distribution:  \n",
    ">   \n",
    ">   $$\n",
    ">   \\text{Geometric}(1/M).\n",
    ">   $$  \n",
    "\n",
    "We choose the smallest possible $M$ in order to have as little draws as possible \n",
    "$$\n",
    "M = \\underset{x \\in \\Omega}{\\sup} \\; \\frac{f(x)}{g(x)}\n",
    "$$\n",
    "\n",
    "<u>Remark</u> : \n",
    "\n",
    "Because $N$ is fixed, that's actually a max. \n",
    "\n",
    "$$ M = \\underset{x \\in \\Omega}{\\max} \\; \\frac{f(x)}{g(x)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple rejection algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import math\n",
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import geom\n",
    "import time\n",
    "from scipy.stats import chisquare\n",
    "from scipy.stats import qmc\n",
    "\n",
    "from source import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although theoritically this algorithm sample from $CB(p,I)$ we can also check empirically that this algorithm does sample from $CB(p,I)$. To do this we used the $\\chi^2$ test of adequation with null hypothesis that the sample follows $CB(p,I)$ with signifiance level of 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "I = 4\n",
    "p = np.random.uniform(0, 1, N)\n",
    "sampler = rejection_sampler(p, I)\n",
    "sampler.sample_generator(1000)\n",
    "p_value = sampler.chi_squared_adequation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result coherent, we have a sampler from $CB(p,I)$ We can then study the law that the p-value of this test follows. To do so we plotted the empirical density of the p-value of the $\\chi^2$ test follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =[]\n",
    "for i in range(10000):\n",
    "    sampler.sample_generator(250)\n",
    "    p_value = sampler.chi_squared_adequation(False)\n",
    "    s.append(p_value)\n",
    "\n",
    "heights, bin_edges, patches = plt.hist(s, bins=100, density=True, alpha=0.6,\n",
    "                                       color='skyblue', edgecolor='gray', label='Empirical Density')\n",
    "\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Empirical Density Function (Histogram)')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at this density, it seems the p-value of the $\\chi^2$ test follows $a * \\delta_0 + b* \\delta_1$ avec $a+b = 1$ et $a<b$ The following code lets us approximate $a$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heights, bin_edges, patches = plt.hist(s, bins=1000, density=True, alpha=0.6,\n",
    "                                       color='skyblue', edgecolor='gray', label='Empirical Density')\n",
    "plt.close()\n",
    "# Compute bin widths\n",
    "bin_widths = bin_edges[1:] - bin_edges[:-1]\n",
    "\n",
    "# Area = height * width\n",
    "first_bin_area = heights[0] * bin_widths[0]\n",
    "last_bin_area = heights[-1] * bin_widths[-1]\n",
    "print(\"a:\", first_bin_area)\n",
    "print(\"b:\", last_bin_area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main draw back of algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main draw back of this approach is that it has a great time complexity. Indeed, the number of draws before acceptance of a sample follows a geometric laws of parameter $1/M$ so we have a sampling time in $O(M)$. The following graph, showcasing the empirical density of the number of draws before acceptance against the theoritical density of $Geom(1/M)$ show that the number of draws before acceptance does follow this law empirically. With our implementation, we choose the smallest possible $M$. This makes it so that the sampling is the quickest possible but at the initial cost of calculation of $M$. With our implementation the initial calculation of $M$ has a time complexity of $O(C_I^N)$. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 13\n",
    "I = 4\n",
    "p = np.random.uniform(0, 1, N)\n",
    "sampler = rejection_sampler(p, I)\n",
    "sampler.sample_generator(20000)\n",
    "sampler.plot_acceptance_density()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said, previously, the sampling is done $O(M)$ However, we do not know Ã  priori the value of $M$ because it's a function of $(p_1, \\dots, p_N, I)$. In the following passage, we will show that:\n",
    " - $M$ tends to grow as $N$ grows (for a fixed $I$)\n",
    " - the variability of $M$ grows exponentially as $N$ grows (which is to be expected as we add degrees of liberty in the function)\n",
    " - $M$ is not monotonic in I (for a fixed $p$) in particular  we have the smallest $M$ as $I \\approx \\sum_i p_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution of M with respect to N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To study the evolution of M with respect to $N$, for a $I$ we will take different $(p_1,\\dots,p_N)$ by drawing each $p_i$ indepdantly and uniformly from $(0,1)$ times and then calculate $M$ for these $p$s.\n",
    "\n",
    "The following boxplot for $I=3$ show the general dynamic of $M$. $M$ increase as $N$ increase (we can see that by looking at the median of $M$). We also note that for a given $(N,I)$ the repartition of $M$ is skewed (with positive skewness)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = 3\n",
    "num_samples = 500  # Number of samples to run\n",
    "N_values = range(7,13)  # Different values for N\n",
    "M_values_all = []  # To hold M values for each N\n",
    "\n",
    "# Collect M values across multiple samples for different N\n",
    "for N in N_values:\n",
    "    M_values = []\n",
    "    for _ in range(num_samples):\n",
    "        p = np.random.uniform(0, 1, N)  # Generate random probabilities p\n",
    "        sampler = rejection_sampler(p, I)\n",
    "        M_values.append(sampler.M)\n",
    "    M_values_all.append(M_values)\n",
    "\n",
    "# Create a boxplot for each N\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(M_values_all, labels=[f'N={N}' for N in N_values], showfliers=False, showmeans=False)\n",
    "plt.title(f'Boxplot of M Values for Different N for I = {I}')\n",
    "plt.ylabel('M')\n",
    "plt.xlabel('N')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore the variability of $M$ also increase exponentially as $N$. We looked at the interquartile range and noted that it increased at an exponential rate of approximately $1.2$ for $I=3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(M_values_all)-1):\n",
    "    iqr_1 = np.percentile(M_values_all[i], 75) - np.percentile(M_values_all[i], 25) \n",
    "    iqr_2 = np.percentile(M_values_all[i+1], 75) - np.percentile(M_values_all[i+1], 25) \n",
    "    print(f\"growth rate of interquartile range between N = {i+7} and N= {i+8} of {round((iqr_2-iqr_1)/iqr_1,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we traced, the same graphic for different values of $I$ to verify that the dynamic of $M$ with respect to $N$ holds for $I \\neq 3$. The identified dynamic seems to hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 500  # Number of samples to run\n",
    "N_values = range(10, 15)  # Different values for N\n",
    "I_values = [1, 2, 4, 5]  # Different values for I (to apply the code to multiple I)\n",
    "\n",
    "# Calculate the grid size (square-like)\n",
    "num_plots = len(I_values)\n",
    "rows = int(math.ceil(math.sqrt(num_plots)))\n",
    "cols = int(math.ceil(num_plots / rows))\n",
    "\n",
    "# Prepare the figure for subplots arranged in a square\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(10, 6))\n",
    "\n",
    "# Flatten the axes array to easily index for plotting\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Collect M values for different I\n",
    "for idx, I in enumerate(I_values):\n",
    "    M_values_all = []\n",
    "    \n",
    "    for N in N_values:\n",
    "        M_values = []\n",
    "        for _ in range(num_samples):\n",
    "            p = np.random.uniform(0, 1, N)  # Generate random probabilities p\n",
    "            sampler = rejection_sampler(p, I)\n",
    "            M_values.append(sampler.M)\n",
    "        M_values_all.append(M_values)\n",
    "\n",
    "    # Create a boxplot for each I on the corresponding subplot\n",
    "    ax = axes[idx]\n",
    "    ax.boxplot(M_values_all, labels=[f'N={N}' for N in N_values], showfliers=False, showmeans=False)\n",
    "    ax.set_title(f'Boxplot of M Values for Different N (I = {I})')\n",
    "    ax.set_ylabel('M')\n",
    "    ax.set_xlabel('N')\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evolution of M with respect to I and $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intuition told us that the evolution of $M$ would be extremly dependent on the $p_i$s. Indeed if we take the edge case where $I$ $p_i$s are equal to 1 and the rest are 0, the sampling should be immediate as its deterministic, on the other hand if, for a given $I$, all the $p_i$s tended to be near 1, it would take a long time before accepting a sample.\n",
    "\n",
    "To see how, $M$ evolved with respect to $I$ and $p$ we thus traced, for a fixed $p$, $M(I)$. This graphic looked like a smile and after calculation its lowest point always seemed near $\\sum_i p_i$. Below, you can see a close up of this graphic with the added indication of $\\sum_i p_i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 17\n",
    "p = np.random.uniform(0,1,N) \n",
    "sum_p = p.sum()\n",
    "values =[]\n",
    "for i in range(N-1):\n",
    "    values.append(rejection_sampler(p,i+1).M)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_values = np.arange(1, N)  # x values start from 1 and go up to N-1\n",
    "l = 4  # Example value for l\n",
    "\n",
    "# Filter values where |x - a| < l\n",
    "filtered_indices = np.abs(x_values - sum_p) < l\n",
    "filtered_x_values = x_values[filtered_indices]\n",
    "filtered_values = np.array(values)[filtered_indices]\n",
    "\n",
    "# Create a line plot for the filtered series\n",
    "plt.plot(filtered_x_values, filtered_values, label='M')\n",
    "\n",
    "plt.axvline(x=sum_p, color='r', linestyle='--', label=f'sum_p = {sum_p}')\n",
    "plt.text(sum_p, min(filtered_values)+1, 'sum_p', color='r', ha='left', va='bottom', fontsize=10)\n",
    "# Add labels and title\n",
    "plt.xlabel('I')\n",
    "plt.ylabel('M')\n",
    "plt.title('evolution of M for different I for p fixed')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "Implementation of the algorithm.This exact algorithm samples from $CB(p,I)$ using the chain rule, by sequentially sampling each marginal variable one at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "I = 4\n",
    "p = np.random.uniform(0, 1, N)\n",
    "sampler = exact_sampler(p, I)\n",
    "sampler.sample_generator(1000)\n",
    "p_value = sampler.chi_squared_adequation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class exact_sampler(sampler):\n",
    "#     def __init__(self, p, I):\n",
    "#         super().__init__(p, I)\n",
    "#         self.q = self._compute_q()\n",
    "#         pass\n",
    "    \n",
    "#     def _compute_q(self, N = None, I = None):\n",
    "#         if I is None:\n",
    "#             I = self.I\n",
    "#         if N is None:\n",
    "#             N = self.N\n",
    "        \n",
    "#         q = np.zeros((I+1,N))\n",
    "        \n",
    "#         for n in range(N):\n",
    "#             q[0][n] = np.prod( 1 - self.p[n:])\n",
    "        \n",
    "#         q[1][N - 1] = self.p[N - 1]\n",
    "        \n",
    "#         for n in range(N - 2, -1, -1):\n",
    "#             for i in range(1, min(I, N - n) + 1):\n",
    "#                 q[i][n] = self.p[n] * q[i - 1][n + 1] + (1 - self.p[n]) * q[i][ n + 1 ]\n",
    "        \n",
    "#         return q\n",
    "    \n",
    "#     def _sample_one(self):\n",
    "#         X = np.zeros(self.N, dtype = int)\n",
    "#         i_n_min_1 = 0\n",
    "#         for n in range(self.N - 1):\n",
    "#             prob = self.p[n] * self.q[self.I - i_n_min_1 - 1][n+1] / self.q[self.I - i_n_min_1][n]\n",
    "#             if np.random.rand() <= prob:\n",
    "#                 X[n] = 1\n",
    "#                 i_n_min_1 += 1\n",
    "#                 if i_n_min_1 == self.I:\n",
    "#                     break\n",
    "#         if i_n_min_1 != self.I:\n",
    "#             X[-1] = 1\n",
    "#         return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The construction of the matrix in our âsample_conditional_bernoulliâ function is of size $O(N^2)$. Indeed, we know that $I \\alpha N$ at most (because $I \\le \\frac N2$) and so, the double loop is indexed on $\\{1,... N-2\\}$, and then on $\\{1,...,I\\}$ ($I$ proportional to $N$) in the \"best\" case and in the \"worst\" case, the second loop is repeated $N-1$ times. Thus, the complexity of this loop is $O(N^2)$.\n",
    "\n",
    "For the second operation of the algorithm, we just get a loop on $\\{1, \\ldots, n\\}$, thus we get a complexity of $O(N)$.\n",
    "\n",
    "Therefore, we can conclude that the complexity is in order $O(N^2) + O(N) = O(N^2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "We now implement a Markov Chain Monte Carlo (MCMC) algorithm to sample from the conditional Bernoulli distribution $\\mathrm{CB}(p, I)$ defined over the space:\n",
    "\n",
    "$$\n",
    "\\Omega' := \\left\\{ x \\in \\{0,1\\}^N \\mid \\sum_{i=1}^N x_i = I \\right\\}\n",
    "$$\n",
    "\n",
    "We initialize a vector $X \\in \\Omega'$ such that $\\sum X_i = I$. For now, $X$ is <u> not random</u> (we simply permute $I$ ones and $N - I$ zeros). Indeed, $P(X_n = k| \\sum_{i=1}^{N}X_i = N) = 0$ if $k \\ne 1$ and $=1$ if $k=1$. Symmetrically, we obviously get $P(X_n = k| \\sum_{i=1}^{N}X_i = 0) = 0$ if $k \\ne 0$ and $=1$ if $k=0$.\n",
    "\n",
    "Note that we exclude the trivial cases where $I = 0$ or $I = N$, since in those cases, the chain would be constant and there is no randomness:\n",
    "\n",
    "- $\\mathrm{CB}(p, N)$ is concentrated on the vector $(1,\\dots,1)$,\n",
    "- $\\mathrm{CB}(p, 0)$ is concentrated on the vector $(0,\\dots,0)$.\n",
    "\n",
    "At each step, we propose a swap between:\n",
    "- a random index $i_1$ where $X_{i_1} = 1$,\n",
    "- and a random index $i_0$ where $X_{i_0} = 0$,\n",
    "\n",
    "and accept this swap with probability:\n",
    "\n",
    "$$\n",
    "\\alpha = \\min\\left(1, \\frac{p_{i_0}/(1 - p_{i_0})}{p_{i_1}/(1 - p_{i_1})} \\right)\n",
    "$$\n",
    "\n",
    "We denote $Y_n$ the current state of the chain, i.e. $Y_n \\in \\Omega'$.\n",
    "\n",
    "Let $Y_n = x$ and let $S_1(x)$ and $S_0(x)$ be the sets of indices where $x_i = 1$ and $x_i = 0$, respectively. \n",
    "\n",
    "At each iteration, the algorithm:\n",
    "- picks $(i_1, i_0) \\in S_1(x) \\times S_0(x)$,\n",
    "- proposes $x' = x$ with entries $i_1 \\leftrightarrow i_0$ swapped,\n",
    "- accepts this move with a probability that depends **only on $x$ and $x'$**, not on earlier history.\n",
    "\n",
    "Hence, the transition probability:\n",
    "\n",
    "$$\n",
    "P(Y_{n+1} = x' \\mid Y_n = x) = q(x \\to x') \\cdot \\alpha(x, x')\n",
    "$$\n",
    "\n",
    "In fact, we get $(Y_i)_{i \\in [num iterations]}$ is a Markov Chain because $Y_i$ just depend on $Y_{i-1}$, for all $n$. \n",
    "\n",
    "Let's prove it. \n",
    "\n",
    "Let $Y_n = (Y_n^{(1)}, \\ldots, Y_n^{(N)})$ a random variable to $\\Omega' = \\big\\{x \\in \\Omega \\mid \\sum_{i=1}^Nx_i = I \\big\\}$ and $i \\in [N]$. Let also the set $I_n \\in [N]$ which represent the index $(i)$ where $Y_i^{(i)} = 1$, this set <u>just depend on $Y_i$</u>.\n",
    "\n",
    "Let $i \\in [N], k$ an integer :\n",
    "\n",
    "\\begin{align*}\n",
    "    P(Y_{k+1}^{(i)} = 1)&=P(Y_{k}^{(i)} = 0)[P(Y_{k+1}^{(i)} = 1| Y_{k}^{(i)} = 0)] + P(Y_{k}^{(i)} = 1)[P(Y_{k+1}^{(i)} = 1| Y_{k}^{(i)} = 1)]\\\\\n",
    "    &= \\frac{N-I}{N}[1-\\frac{1}{N-I}\\min(1, \\sum_{j\\in I_n} \\frac{1-p_i}{1-p_j})] + \\frac{I}{N}[1-P(Y_{k+1}^{(i)} = 0| Y_{k}^{(i)} = 1)] \\\\\n",
    "    & = \\frac{N-I}{N}[1-\\frac{1}{N-I}\\min(1, \\sum_{j\\in I_n} \\frac{1-p_i}{1-p_j})] + \\frac{I}{N}[1-\\frac 1I \\min(1, \\frac{\\sum_{i \\in I_n^c}1-p_j}{1-p_i})]\n",
    "\\end{align*}\n",
    "\n",
    "(Note that we could just left the value $P(Y_{k}^{(i)} = 0)$ to show the property)\n",
    "\n",
    "With the same reasoning on $P(Y_{k+1}^{(i)}=0)$, we can conclude that ($Y_i$) is a Markov chain, because it just depend on the previous value of $Y_{k-1}$. \n",
    "\n",
    "So, $(Y_i)$ does depend only on the **current state** $x = Y_n$.  \n",
    "\n",
    "\n",
    "Therefore, the process $(Y_n)_{n\\geq 0}$ satisfies the **Markov property**:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(Y_{n+1} \\mid Y_n, Y_{n-1}, \\dots, Y_0) = \\mathbb{P}(Y_{n+1} \\mid Y_n)\n",
    "$$\n",
    "\n",
    "- The MCMC algorithm uses **local proposals** (1-to-0 and 0-to-1 swaps),\n",
    "- The chain is **Markovian** by construction,\n",
    "\n",
    "We can now use this chain to sample approximately from the conditional Bernoulli distribution $\\mathrm{CB}(p, I)$. (See the proof below)\n",
    "\n",
    "\n",
    "<!-- ---\n",
    "\n",
    "Let's implement the MCMC (Markov Chain Monte Carlo).\n",
    "\n",
    "For this, we initialize a vector $X$ which respect the condition $\\sum_{i=1}^{N}X_i = I$ (for the moment, X is NOT random). After, if I isn't equal to $0$ or $N$ (because there is no random with that configuration), indeed, $P(X_n = k| \\sum_{i=1}^{N}X_i = N) = 0$ if $k \\ne 1$ and $=1$ if $k=1$. Symmetrically, we obviously get $P(X_n = k| \\sum_{i=1}^{N}X_i = 0) = 0$ if $k \\ne 0$ and $=1$ if $k=0$.\n",
    "\n",
    "Afterward, we just \"swap\" the different element of our vector $X$ with probability \"$\\min(1,\\frac{w_{i_0}}{w_{i_1}})$\" like it is indicated in the paper.\n",
    "\n",
    "In this algorithm,\n",
    "$(Y_i)_{i \\in [num iterations]}$ is a Markov Chain because $Y_i$ just depend on $Y_{i-1}$, for all $n$. Let's prove it. Let $Y_n = (Y_n^{(1)}, \\ldots, Y_n^{(N)})$ a random variable to $\\Omega' = \\big\\{x \\in \\Omega \\mid \\sum_{i=1}^Nx_i = I \\big\\}$ and $i \\in [N]$. Let also the set $I_n \\in [N]$ which represent the index $(i)$ where $Y_i^{(i)} = 1$, this set <u>just depend on $Y_i$</u>.\n",
    "\n",
    "Let $i \\in [N], k$ an integer :\n",
    "\n",
    "\\begin{align*}\n",
    "    P(Y_{k+1}^{(i)} = 1)&=P(Y_{k}^{(i)} = 0)[P(Y_{k+1}^{(i)} = 1| Y_{k}^{(i)} = 0)] + P(Y_{k}^{(i)} = 1)[P(Y_{k+1}^{(i)} = 1| Y_{k}^{(i)} = 1)]\\\\\n",
    "    &= \\frac{N-I}{N}[1-\\frac{1}{N-I}\\min(1, \\sum_{j\\in I_n} \\frac{1-p_i}{1-p_j})] + \\frac{I}{N}[1-P(Y_{k+1}^{(i)} = 0| Y_{k}^{(i)} = 1)] \\\\\n",
    "    & = \\frac{N-I}{N}[1-\\frac{1}{N-I}\\min(1, \\sum_{j\\in I_n} \\frac{1-p_i}{1-p_j})] + \\frac{I}{N}[1-\\frac 1I \\min(1, \\frac{\\sum_{i \\in I_n^c}1-p_j}{1-p_i})]\n",
    "\\end{align*}\n",
    "\n",
    "(Note that we could just left the value $P(Y_{k}^{(i)} = 0)$ to show the property)\n",
    "\n",
    "With the same reasoning on $P(Y_{k+1}^{(i)}=0)$, we can conclude that ($Y_i$) is a Markov chain, because it just depend on the previous value of $Y_{k-1}$. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcmc_conditional_bernoulli(p, I : int, num_iterations : int):\n",
    "    p = np.array(p)\n",
    "    N = len(p)\n",
    "    # Let's make a X which respect the constraint sum X_i = I\n",
    "    X = np.zeros(N, dtype=int)\n",
    "    X[:I] = 1\n",
    "    np.random.shuffle(X)\n",
    "    odds = p / (1 - p)\n",
    "    S0 = list(np.where(X == 0)[0])\n",
    "    S1 = list(np.nonzero(X)[0])\n",
    "    \n",
    "    for nb_iter in range(num_iterations):\n",
    "        # random selection of 1 and 0\n",
    "        np.random.shuffle(S0)\n",
    "        np.random.shuffle(S1)\n",
    "\n",
    "        # let's take a random element of our index_0/1\n",
    "        i = S1.pop()\n",
    "        j = S0.pop()\n",
    "\n",
    "        # Compute the probability of acceptance\n",
    "        acceptance_prob = min(1, odds[j] / odds[i])\n",
    "\n",
    "        # reject or acceptance's swap\n",
    "        if np.random.rand() < acceptance_prob: # \"accept with probability acceptance_prob\"\n",
    "            X[i], X[j] = 0, 1\n",
    "            S0.append(i)\n",
    "            S1.append(j) \n",
    "        else : #restores origninals values else\n",
    "            S0.append(j)\n",
    "            S1.append(i)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "x = mcmc_conditional_bernoulli([1/2 for i in range(1_000)],497, 10_000) \n",
    "np.count_nonzero(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why does this algorithm works ? \n",
    "\n",
    "We already proved that $(Y_i)$ is a Markov Chain to $\\Omega'$. Let's suppose that $(Y_n) \\sim h$, we have $\\pi$ the target probability density of $(X_1, \\ldots X_N| \\sum_{i=1}^{N}X_i = I)$. To apply the Metropolis Hastings algorithm, we need to check out the conditions :\n",
    "\n",
    "- (1) $(Y_i)$ is ergodic (irreducible, recurrent, positive, aperiodic) \n",
    "\n",
    "- (2) reversibility : for all $x,y \\in \\Omega', h(x|y) = h(y|x)$, and thus, show that for all $x,y \\in \\{0,1\\}$, we have $\\pi(x)h(x|y) = \\pi(y)h(y|x)$\n",
    "\n",
    "With the Metropolis-Hasting presented below, when (1) and (2) are proven, and using the ergodic theorem we will have shown that $(Y_i)$ converge in law to $CB(p,I)$ because $\\pi$ is the density of $CB(p,I) $\n",
    "\n",
    "\n",
    "the **Markov chain** $(Y_i)_{i \\geq 0}$ on $\\Omega'$ with:\n",
    "\n",
    "- Initial state $Y_0 \\in \\Omega'$, sampled uniformly.\n",
    "- At each iteration $i$, choose a pair $((i,j))$ such that:\n",
    "  - $j1 \\in S_1(Y_i) $ (i.e., $ Y_i[j1] = 1 $),\n",
    "  - $j0 \\in S_0(Y_i) $ (i.e., $ Y_i[j0] = 0 $),\n",
    "- Propose a **swap**: define $(Y_i')_{i \\ge 0}$ by exchanging $Y_i[j0] \\leftrightarrow Y_i[j1]$.\n",
    "- Accept $Y_i'$ with probability:\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\alpha(Y_i, Y_i') = \\min\\left(1, \\frac{\\pi(Y_i')}{\\pi(Y_i)}\\right) = \\min\\left(1, \\frac{\\text{odds}_{j0}}{\\text{odds}_{j1}} \\right)\n",
    "}\n",
    "\\quad \\text{where } \\text{odds}_{j0} := \\frac{p_{j0}}{1 - p_{j0}}\n",
    "$$\n",
    "\n",
    "Then, $Y_{i+1} = Y_i'$ with probability $\\frac{p_{j0}}{1 - p_{j1}}$ and $Y_{i+1} = Y_i$ elsewhere.\n",
    "\n",
    "\n",
    "And thus, if we proved (1) and (2), we we proved the efficiency of our algorithm thanks to Metropolis Hastings which ensures us that $Y_i \\overset{\\text{(d)}}{\\underset{i \\to \\infty}{\\longrightarrow}} \\pi $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u> Proof :</u>\n",
    "\n",
    "- (1) Because $N$ is finite, $\\Omega'$ is also finite and $(Y_i)_{i \\ge 0}$ is a Markov chain irreducible (clearly, because, all the state of $\\Omega'$ are available and communicate) to $\\Omega'$ finite. Thus we can say that ($Y_i$) is also recurrent and positive. Furthermore, for all state $x \\in \\Omega'$, we can find a period stay to this stat with probability not null, and thus, our chain $(Y_i)_{i \\ge 0}$ is aperiodic. Thus $(Y_i)_{i \\ge 0}$ is an ergodic Markov Chain and so does converge to it's invariant probability $\\pi$.\n",
    "\n",
    "- (2) $h$ is the probability density of $(Y_i)_{i \\ge 0}$, because the problem is symmetrical, that is clear that for all $x,y \\in \\Omega'$, we get \n",
    "\n",
    "$$h(x|y) = P(Y_{k+1} = x|Y_k = y) = P(Y_{k+1} = y|Y_k = x) = h(y|x)$$\n",
    "\n",
    "Thus, because $\\pi(x)$ is the density of $X_1, \\ldots, X_n | \\sum_{i=1}^nX_i=I$, we get \n",
    "\n",
    "$$\\pi(x)\\alpha \\frac{dP_{X_1, \\ldots, X_n}(x,I)}{d \\mu \\otimes \\mu} \\alpha \\Pi_{i=1}^N p_i^{X_i}(1-p_i)^{1-X_i} = \\Pi_{i=1}^N (\\frac{p_i}{1-p_i})^{X_i}(1-p_i) = \\Pi_{i=1}^N(1-p_i) \\times \\Pi_{i=1}^N (\\frac{p_i}{1-p_i})^{X_i} \\alpha \\Pi_{i=1}^N (\\frac{p_i}{1-p_i})^{X_i} =  \\Pi_{i=1}^N (\\text{odds}_i)^{X_i}$$\n",
    "\n",
    " (with $\\mu$ the counting measuring). So, we can now conclude because let $x,y \\in \\Omega'$, we get \n",
    "\n",
    "\\begin{align*}\n",
    "    \\pi(x)h(x|y) &= \\pi(y)h(y|x)\\\\\n",
    "    \\iff \\pi(x)&=\\pi(y)\\\\\n",
    "    \\iff \\frac{p_i^{X_i}(1-p_i)^{1-X_i}}{p_i^{X_i}(1-p_i)^{1-X_i}} &= 1\n",
    "\\end{align*}\n",
    "\n",
    "What is True, so, by the explanation after (1) and (2) in the previous markdown, we showed why this algorithms works. Thus we well have \n",
    "\n",
    "$$\\boxed{Y_i \\overset{\\text{(d)}}{\\underset{i \\to \\infty}{\\longrightarrow}} \\pi} $$\n",
    "\n",
    "According to the previous statement, we get $(Y_i)$ converges in distribution to $\\pi$, the **unique stationary distribution**.\n",
    "\n",
    "- The chain moves **only within the constrained set**  $\\Omega'$.\n",
    "- Each transition corresponds to swapping a 1 and a 0 â preserving the total number of 1's.\n",
    "- The **odds ratios** act as importance weights that guide the chain toward configurations favored by \\( p \\).\n",
    "- The Markov chain thus **explores the correct target distribution** over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to asses the mixing of our chain $(Y_i)$ ?\n",
    "\n",
    "\n",
    "#### first strategy \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the mixing of our Chain, and so, know if $(Y_i)$ visit well all the possible states, we use a **coupling-based strategy**. This permit to evaluate the meeting time of two chain $(Y_i), (\\tilde Y_i)$ and thus, determine the level of mixing of our algorithm. $ (\\tilde Y_i)$ start in an arbitrary state, different from $(Y_i)$. And then, compute the minimum time of meeting of those two chain. The main purpose of the paper is about a non identical distribution of $(p_1, \\ldots p_N)$ thus we'll compute the meeting time in this situation.\n",
    "\n",
    "The main goal here is to assess the velocity of convergence of $(Y_i)$ with our mcmc algorithm.\n",
    "\n",
    "To explain our approach, this algorithm is based on the statement : if two copy of Markov chain $ (Y_i)_{i \\ge 1}$  and $ (\\tilde Y_i)_{i \\ge 1}$ evolve together but from different states, and end up meeting, we can deduce that one of them is near of the other, and thus, there are near there limit law $\\pi$. We already proved why our Markov chain is converging to the conditional Bernoulli law, according to the Metropolis Hastings algorithm, so we can use the convergence of our two Markov chain.\n",
    "\n",
    "\n",
    "Moreover, we can arg a little bit more mathematically, if we the state that \n",
    "\n",
    "- $ (Y_i)$, starting from an arbitrary state $ x \\in \\Omega'$,\n",
    "- $ (\\tilde{Y}_i) $, starting from a different state $ \\tilde{x} \\in \\Omega'$ at **Hamming distance 2** from $( x )$.\n",
    "\n",
    "We then run both chains simultaneously using a **maximally coupled transition kernel**, and we record the **first time** they meet (i.e., become equal). This time is called the **meeting time**, denoted :\n",
    "\n",
    "$$\\boxed{\\tau := \\inf\\big\\{ t \\ge 1 \\mid Y_t = \\tilde Y_t \\big\\}}$$ \n",
    "\n",
    "This approach is based on the fundamental coupling inequality:\n",
    "\n",
    "$$\\lVert \\text{Law}(Y_t) - \\pi \\rVert_{\\mathrm{TV}} \\leq \\mathbb{P}(Y_t \\neq \\tilde{Y}_t)$$\n",
    "\n",
    "Moreover, this probability is estimated by averaging over multiple simulations:\n",
    "\n",
    "$$ \\{\\omega \\mid Y_t(\\omega) \\neq \\tilde{Y}_t(\\omega) \\}= \\{\\omega \\mid \\tau(\\omega) > t \\}  \\quad \\implies \\quad \\mathbb{P}(Y_t \\neq \\tilde{Y}_t) = \\mathbb{P}(\\tau > t) $$\n",
    "\n",
    "In practice, we generate many coupled pairs $(Y_i, \\tilde{Y}_i)$, compute the corresponding meeting times $( \\tau_i )$, and choose the smallest time $ t$ such that:\n",
    "\n",
    "$$\\frac{1}{M} \\sum_{i=1}^M \\mathbf{1}_{\\{\\tau_i > t\\}} \\leq \\varepsilon$$\n",
    "\n",
    "Note that here, $\\tau_i$ are deterministic, (after computing), to avoid an abuse of language, we can say this is \"knowing $\\tau_i$\". In other word :\n",
    "\n",
    "$$\\lVert \\text{Law}(Y_t))-\\pi \\rVert_{TV}  \\le P(Y_t \\ne \\tilde Y_t) \\le \\mathbb{E}(\\mathbb{1}_{d^{(t)} > 0}) = P(d^{(t)} > 0) = P( \\tau >t)$$\n",
    "\n",
    "\n",
    "This procedure helps assess how fast two initially distinct trajectories \"forget\" their initial state and converge to the same stationary distribution, providing insight into the convergence rate of the algorithm under non-uniform probability vectors $p_1 \\ldots p_N$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_mcmc(x, y, p):\n",
    "    \"\"\"\n",
    "    return the common swap of x,y like the function mcmc_conditional_bernoulli for just one iteration.\n",
    "    That function DOES NOT WORKS if I=N or I=0, but in this case, there is no need to check the mixing. \n",
    "    \"\"\"\n",
    "    x, y = x.copy(), y.copy()\n",
    "    odds = p / (1 - p)\n",
    "    # Making the different set presented in 2.2\n",
    "    S0_x = list(np.where(x == 0)[0])\n",
    "    S1_x = list(np.nonzero(x)[0])\n",
    "    S0_y = list(np.where(y == 0)[0])\n",
    "    S1_y = list(np.nonzero(y)[0])\n",
    "    if len(S0_x) == 0 or len(S1_x) == 0 or len(S0_y) == 0 or len(S1_y) == 0:\n",
    "        raise ValueError(\"Invalid swap set: one of the chains has I = 0 or I = N.\")\n",
    "\n",
    "    # Maximal coupling for i0\n",
    "    common_S0 = list(set(S0_x) & set(S0_y)) \n",
    "    alpha0 = min(len(common_S0) / len(S0_x), len(common_S0) / len(S0_y))\n",
    "    # Choose a random i, in common S_0, more we have commmon values, more we would choose them\n",
    "    if len(common_S0) > 0 and np.random.rand() < alpha0:\n",
    "        i0 = np.random.choice(common_S0) \n",
    "        j0 = i0\n",
    "    else:\n",
    "        diff_x = list(set(S0_x) - set(S0_y))\n",
    "        diff_y = list(set(S0_y) - set(S0_x))\n",
    "        i0 = np.random.choice(diff_x)\n",
    "        j0 = np.random.choice(diff_y)\n",
    "\n",
    "    # Maximal coupling for i1, same as the previous loop\n",
    "    common_S1 = list(set(S1_x) & set(S1_y))\n",
    "    alpha1 = min(len(common_S1) / len(S1_x), len(common_S1) / len(S1_y))\n",
    "    if len(common_S1) > 0 and np.random.rand() < alpha1:\n",
    "        i1 = np.random.choice(common_S1)\n",
    "        j1 = i1\n",
    "    else:\n",
    "        diff_x = list(set(S1_x) - set(S1_y))\n",
    "        diff_y = list(set(S1_y) - set(S1_x))\n",
    "        i1 = np.random.choice(diff_x)\n",
    "        j1 = np.random.choice(diff_y)\n",
    "\n",
    "    u = np.random.rand()\n",
    "    if u < min(1, odds[i0] / odds[i1]):\n",
    "        x[i0], x[i1] = 1, 0\n",
    "    if u < min(1, odds[j0] / odds[j1]):\n",
    "        y[j0], y[j1] = 1, 0\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def initial_state_hammer(I : int, N : int):\n",
    "    \"\"\" \n",
    "    generate two random vectors x,y which follow x_1+ ... + x_N = I, y_1+ ... + y_N =I AND d(x,y) = somme 1(x_i != y_i) = 2\n",
    "    \"\"\"\n",
    "    x = np.array([1]*I + [0]*(N-I))\n",
    "    np.random.shuffle(x)\n",
    "\n",
    "    idx_1 = np.where(x == 1)[0]\n",
    "    idx_0 = np.where(x == 0)[0]\n",
    "    i1 = np.random.choice(idx_1)\n",
    "    i0 = np.random.choice(idx_0)\n",
    "\n",
    "    y = x.copy()\n",
    "    y[i1], y[i0] = 0, 1\n",
    "\n",
    "    return x,y\n",
    "    \n",
    "def meeting_time(epsilon : float, M : int, I : int, p, L=1):\n",
    "    \"\"\"\n",
    "    Let L be the lag, epsilon the error, M the number of iteration, I like before\n",
    "    \"\"\"\n",
    "    p = np.array(p)\n",
    "    N = len(p)\n",
    "    meeting_time = []\n",
    "    \n",
    "    for _ in range(M) :\n",
    "        x,y = initial_state_hammer(I,N)\n",
    "        tau = 0\n",
    "        while True :\n",
    "            x,y = swap_mcmc(x,y,p)\n",
    "            tau += 1\n",
    "            if np.array_equal(x, y): \n",
    "                meeting_time.append(tau)\n",
    "                break\n",
    "    t = 0\n",
    "    #print(np.mean(meeting_time), np.max(meeting_time), np.min(meeting_time))\n",
    "    while True :\n",
    "        total_variation_t = np.mean([max(0, np.ceil((tau_i - L - t) / L)) for tau_i in meeting_time])\n",
    "        if total_variation_t <= epsilon :\n",
    "            return t\n",
    "        t +=1\n",
    "\n",
    "def probability_generator(N : int): \n",
    "    p = np.array([np.random.uniform(0,1) for _ in range(N)])\n",
    "    return p\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test : samples = [X.copy()]  # Collect samples \n",
    "\n",
    "p = probability_generator(100)\n",
    "\n",
    "meeting_time(epsilon=0.01,M=500,I=45,p=p) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we checked that the mixing time is approximately in order $N \\log(N)$. Let's see it with a plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hamming_distance(x, y):\n",
    "    return np.sum(x != y)\n",
    "\n",
    "def simulate_convergence(I, N, p, M=500, max_steps=100): # max step to avoid infinite loop\n",
    "    distances = np.zeros((M, max_steps))\n",
    "\n",
    "    for m in range(M):\n",
    "        x, y = initial_state_hammer(I, N)\n",
    "        for t in range(max_steps):\n",
    "            distances[m, t] = hamming_distance(x, y)\n",
    "            if np.array_equal(x, y):\n",
    "                # stay at 0 after meeting\n",
    "                distances[m, t:] = 0\n",
    "                break\n",
    "            x, y = swap_mcmc(x, y, p)\n",
    "\n",
    "    # Mean on the M-trajectory\n",
    "    mean_dist = distances.mean(axis=0)\n",
    "    return mean_dist\n",
    "\n",
    "# Parameters\n",
    "N = 50\n",
    "I = 25\n",
    "p = probability_generator(N)\n",
    "M = 500       \n",
    "max_steps = 100\n",
    "\n",
    "# Simulation\n",
    "mean_hamming = simulate_convergence(I, N, p, M=500, max_steps=max_steps)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(mean_hamming, label='Average Hamming distance')\n",
    "plt.xlabel(\"Time (iterations MCMC)\")\n",
    "plt.ylabel(\"Average Hamming distance\")\n",
    "plt.title(f\"Convergence of the coupled chain (N={N}, I={I})\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see a boxplot to understand the distribution and the reliability of that algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meeting_times(I, N, p, M=500, max_steps=1000): # max step to avoid infinite loop\n",
    "    meeting_times = []\n",
    "    for _ in range(M):\n",
    "        x, y = initial_state_hammer(I, N)\n",
    "        for t in range(max_steps):\n",
    "            if np.array_equal(x, y):\n",
    "                meeting_times.append(t)\n",
    "                break\n",
    "            x, y = swap_mcmc(x, y, p)\n",
    "        else:\n",
    "            meeting_times.append(max_steps)  \n",
    "    return meeting_times\n",
    "\n",
    "# Boxplot\n",
    "I = 50\n",
    "N = 100\n",
    "M = 500\n",
    "p = probability_generator(N)\n",
    "\n",
    "meeting_times = get_meeting_times(I=I, N=N, p=p,)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(meeting_times, vert=False, patch_artist=True)\n",
    "plt.title(f\"Distribution of meeting times N={N} and I={I}, for {M} iterations\")\n",
    "plt.xlabel(\"Iteration untill coupling\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we notice that in average, for $N=100$, we get a meeting time lower than $100\\times \\log(100)$ this is an efficient mixing !  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though we already have answered this question, we can still propose another way to compute the mixing of the algorithm. The main problem with the previous method is the constraint $\\mathbb X_{\\text{adj}}$ where the Hammer distance is bounded on two. We propose another version where we have $(x)^{(t)}$, $(\\tilde x)^{(t)}$ with $x^{(0)} \\in \\Omega'$ and $\\tilde x \\sim CB(p,I)$, here we will apply the same logical, the same changes for those two chain, and compute the average time meeting. \n",
    "\n",
    "The advantage of that method is to not constraint us to this $\\mathbb X_{\\text{adj}}$ but the drawbacks is that it is more expansive to compute. We also propose another way to compute the distance, more easy to compute. $P(\\tau>t) = \\hat d_{TV} $ here, and it is totally okay according to the inequality above.\n",
    "\n",
    "\n",
    "Mathematically, to explain our method : \n",
    "\n",
    "Let:\n",
    "- $x^{(0)} \\in \\Omega'$ be an arbitrary initial state such that $\\sum x_i = I$,\n",
    "- $\\tilde{x}^{(0)} \\sim \\text{CB}(p, I)$, drawn from the true target distribution.\n",
    "\n",
    "Then, we evolve both chains $(x^{(t)})_{t \\geq 0}$ and $(\\tilde{x}^{(t)})_{t \\geq 0}$ **using the same coupled transition kernel** (as before), and record the **first time $\\tau$ such that $x^{(\\tau)} = \\tilde{x}^{(\\tau)}$**.\n",
    "\n",
    "This method is simpler to implement, since we do not require the chains to be initialized at a specific distance, and the coupling mechanism is the same.\n",
    "\n",
    "According to the coupling inequality, we still have:\n",
    "\n",
    "$$\n",
    "\\lVert \\text{Law}(x^{(t)}) - \\pi \\rVert_{TV} \\leq \\mathbb{P}(x^{(t)} \\neq \\tilde{x}^{(t)}) = \\mathbb{P}(\\tau > t)\n",
    "$$\n",
    "\n",
    "So by estimating $\\mathbb{P}(\\tau > t)$ empirically, we directly obtain an **upper bound** on the total variation distance to stationarity.\n",
    "\n",
    "Letting $\\hat{\\tau}_1, \\dots, \\hat{\\tau}_M$ be $M$ i.i.d. meeting times, we approximate:\n",
    "\n",
    "$$\n",
    "\\hat{d}_{TV}(t) := \\frac{1}{M} \\sum_{i=1}^M \\mathbf{1}_{\\hat{\\tau}_i > t}\n",
    "$$\n",
    "\n",
    "and return the **smallest $t$ such that $\\hat{d}_{TV}(t) \\leq \\varepsilon$**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state(I : int, N : int):\n",
    "    \"\"\" \n",
    "    generate random vector x which follow x_1+ ... + x_N = I\n",
    "    \"\"\"\n",
    "    x =np.array([1]*I + [0]*(N-I))\n",
    "    np.random.shuffle(x)\n",
    "    return x\n",
    "\n",
    "def alternative_mcmc_meeting_time(epsilon : float, M : int, I : int, p):\n",
    "    \"\"\"\n",
    "    Alternative way to compute the mixing of our chain, that's normal that the meeting time is larger than the previous method, we do not restrein us to the case where \n",
    "    the Hammer distance is equal to two. \n",
    "    \"\"\"\n",
    "    p = np.array(p)\n",
    "    N = len(p)\n",
    "    meeting_time = []\n",
    "    for _ in range(M):\n",
    "        tau = 0 \n",
    "        x = initial_state(I,N)\n",
    "        sampler = rejection_sampler(p,I)\n",
    "        sampler.naive_sample()\n",
    "        y = sampler.sample\n",
    "        while True :\n",
    "            x,y = swap_mcmc(x,y,p)\n",
    "            tau += 1\n",
    "            if np.array_equal(x, y): \n",
    "                meeting_time.append(tau)\n",
    "                break\n",
    "    t = 0\n",
    "    while True:\n",
    "        total_variation_t = np.mean([tau > t for tau in meeting_time])\n",
    "        if total_variation_t <= epsilon:\n",
    "            return t\n",
    "        t += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try our alternative algorithm\n",
    "\n",
    "p = probability_generator(100)\n",
    "\n",
    "alternative_mcmc_meeting_time(epsilon=0.01,M=500,I=50,p=p) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, like we would expect, the meeting time is much larger. \n",
    "\n",
    "We can in other hand identify different pros of our method : our algorithm is general, conceptually clean, with no artificial distance constraint subject to requiring a sampling from $\\text{CB}(p,I)$, which can be **computationally costly**... \n",
    "\n",
    "Indeed, meeting times may be larger on average than in the adjacent initialization case.. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we present a third and more theoretically grounded method for estimating the mixing time of our Markov chain.  \n",
    "We implement **Algorithm 1** from the paper _\"Estimating Convergence of Markov Chains with L-Lag Couplings\"_ by Biswas, Jacob, and Vanetti (2019), which provides a way to estimate the **total variation distance** of a Markov chain.\n",
    "\n",
    "\n",
    "We aim to estimate the quantity:\n",
    "\n",
    "$$\n",
    "d_{\\text{TV}}(\\mathcal{L}(x_t), \\pi)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mathcal{L}(x_t)$ is the law of the Markov chain at time $t$,\n",
    "- $\\pi$ is the target distribution (here, the conditional Bernoulli law $\\text{CB}(p, I)$).\n",
    "\n",
    "Since we do not know $\\mathcal{L}(x_t)$ explicitly, we **construct a coupling** between two chains:\n",
    "- $(x_t)$, evolving from an arbitrary initial state in $\\Omega'$,\n",
    "- $(y_{t-L})$, a second chain started from another state and updated in parallel,\n",
    "with a **temporal lag** $L$ between them.\n",
    "\n",
    "So to compute it, we can say that while $(x_t) \\ne (y_{t-L})$, Law $(x_t) \\ne \\pi$. So, we just have to compute the meeting times and look at them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, we simulate the two chains with lag $L$ using the same coupled kernel, and define the **meeting time** $\\tau^{(L)}$ as:\n",
    "\n",
    "$$\\tau^{(L)} = \\inf\\{t \\ge L \\mid x_t = y_{t - L} \\}$$\n",
    "\n",
    "according to the paper, we know that \n",
    "\n",
    "$$d_{\\text{TV}}(\\mathcal{L}(x_t), \\pi) \\le \\mathbb{E}[\\max(0, \\lceil \\frac{\\tau^{(L)}-L-t}{L}\\rceil)] $$\n",
    "\n",
    "This estimator is **guaranteed to upper-bound** the variation distance and is **monotonically decreasing** in $t$.  \n",
    "It provides a **rigorous and practical tool** to quantify convergence.\n",
    "\n",
    "with $\\tau^{(L)}$ the meeting time for lag $L$. Thus, this is obvious that it is decreasing with $t$. This method is for us better than the previous, the hammer method is restricted in the case where the hamming distance is equal to 2, and the second is very expensive to compute. This below algorithm is based on theoretical result guaranteed and is not slow to compute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithm_1_L_lag_coupling(L, M, I, p):\n",
    "    \"\"\"\n",
    "    Implementation of the first algorithm of the paper.\n",
    "    Compute and return the meeting time Ï^{(L)}\n",
    "    \"\"\"\n",
    "    p = np.array(p)\n",
    "    N = len(p)\n",
    "    meeting_times = []\n",
    "\n",
    "    for _ in range(M):\n",
    "        # Initialisation\n",
    "        x = initial_state(I, N)  # X_0\n",
    "        X_chain = [x]\n",
    "        for _ in range(L):  # GÃ©nerate X_1,...,X_L\n",
    "            x = swap_mcmc(x, x, p)[0]\n",
    "            X_chain.append(x)\n",
    "\n",
    "        y = initial_state(I, N)  # Y_0\n",
    "\n",
    "        t = L\n",
    "        while True:\n",
    "            x_new, y_new = swap_mcmc(X_chain[-1], y, p)\n",
    "            X_chain.append(x_new)\n",
    "            y = y_new\n",
    "            if np.array_equal(x_new, y):\n",
    "                meeting_times.append(t)\n",
    "                break\n",
    "            t += 1\n",
    "\n",
    "    return meeting_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_total_variation(tau_L_list, L, t_max):\n",
    "    \"\"\"\n",
    "    Estimate the total variation distance d_{TV}(Ï_t=law(x_t), Ï)\n",
    "    from meeting times Ï^{(L)} for all t â¤ t_max \n",
    "\n",
    "    Return : table numpy with d_TV estimate for t = 0, ..., t_max\n",
    "    \"\"\"\n",
    "    tau_L = np.array(tau_L_list)\n",
    "    M = len(tau_L)\n",
    "    d_tv = []\n",
    "\n",
    "    for t in range(t_max + 1):\n",
    "        # for each t, we compute the contribution max(0, ceil((Ï - L - t) / L)) for each trajectory\n",
    "        individual_bounds = []\n",
    "        for tau in tau_L:\n",
    "            bound = (tau - L - t) / L\n",
    "            bound = max(0,np.ceil(bound))\n",
    "            #print(bound)\n",
    "            individual_bounds.append(bound)\n",
    "\n",
    "        # empirical mean : we asses the uppper bound of d_TV(Ï_t, Ï)\n",
    "        d_tv_t = np.mean(individual_bounds)\n",
    "        d_tv.append(d_tv_t)\n",
    "\n",
    "    return np.array(d_tv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = probability_generator(N=50)\n",
    "meeting_times = algorithm_1_L_lag_coupling(L=1, M=500, I=25, p=p)\n",
    "meeting_times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show as before a histogram to see how are distributed the meeting times, for $M=500$, $I=25$ and $N = 50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(meeting_times, bins=30)\n",
    "plt.xlabel(\"Ï^(L)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of meeting times \\\"L-Lag\\\" \")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we'll show how is decreasing the estimated total variation with number of iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau_L = algorithm_1_L_lag_coupling(L=1, M=500, I=25, p=p)\n",
    "d_tv_values = estimate_total_variation(tau_L, L=1, t_max=300)\n",
    "\n",
    "plt.plot(d_tv_values)\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Estimated TV distance\")\n",
    "plt.title(\"Estimated d_TV(Ï_t, Ï) via L-lag Coupling\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rk: the estimated TV distance is $\\mathbb{E}[\\max(0, \\lceil \\frac{\\tau^{(L)}-L-t}{L}\\rceil)]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we can also identify different pros :\n",
    "\n",
    "- Theoretical Guarantee : Upper bound on $d_{\\text{TV}}$ based on a proven inequality\n",
    "- general and not restricted like the first method\n",
    "- Efficient : Much faster than parallel chain couplings for high accuracy\n",
    "\n",
    "and some cons :\n",
    "\n",
    "-  Requires trajectory storage â One needs to keep $x_0, ..., x_t$ $\\implies$ costly in memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact algorithm (using chain rule) can be adapted to make use of (R)QMC method. To do so, when generating the marginal variable, rather than using a uniform we use a low discrepency sequence (here we choose to implement either Sobol's sequence or Halton's sequence) with an added uniform random shift if we do a randomized quasi monte carlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When testing if these QMC and RQMC sampling method sample from $CB(p,I)$, still using our $\\chi^2$ test we remarked that the QMC algorithm was rejected, while the RQMC was not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "I = 4\n",
    "p = np.random.uniform(0,1,N)\n",
    "sampler = RQMC_sampler(p,I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling using Sobol sequence (RQMC)\n",
    "sampler.sample_generator(1024,sequence=0,RQMC = True)\n",
    "p_val =sampler.chi_squared_adequation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling using Sobol sequence (QMC)\n",
    "sampler.sample_generator(1024,sequence=0,RQMC = False)\n",
    "p_val =sampler.chi_squared_adequation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### advantages of (R)QMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these implementation of sampling method do not provide quicker sampling method (as they are still in $O(N^2)$ due to the initial calculation of the matrix $q$), they should normally offer a quicker convergence rate when using them to approximate an expectation.\n",
    "\n",
    "To test this we tried to approximate $E[X]$ where $X \\sim CB(p,I)$ and traced the error $||E[X] - \\overline{X}_n ||_2$ where $\\overline{X}_n$ is the estimator of $E[X]$ using $X_i$ sampled from one of the three considered algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without surprise:\n",
    " - the exact algorithm (classic monte carlo method) has an error in $O(1/ \\sqrt{n})$ with $n$ the number of sample\n",
    " - both the QMC and RQMC sampling method has error in $O(n^{ \\varepsilon -1})$ (with $\\varepsilon \\approx 0.4$ in our case)\n",
    "\n",
    "We can note that despite the fact that the QMC sampling fail the $\\chi_2$ test, it give a good result when used to approximate $E[X]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2048\n",
    "u = lambda x:x*x\n",
    "E = sampler._calculate_expectation(u)\n",
    "sampler.sample_generator(L,sequence=2)\n",
    "S_exact = sampler.sample\n",
    "sampler.sample_generator(L,sequence=0,RQMC=False)\n",
    "S_sobol = sampler.sample\n",
    "sampler.sample_generator(L,sequence=0,RQMC=True)\n",
    "S_rqmc = sampler.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 50\n",
    "eps = 0.40\n",
    "x_values = np.arange(start, L + 1)\n",
    "\n",
    "plt.plot(x_values, np.array([np.linalg.norm((E - np.mean(S_exact[:i], axis= 0))) for i in range(start,L+1)]), label='exact sampling')\n",
    "plt.plot(x_values, np.array([np.linalg.norm((E - np.mean(S_sobol[:i], axis= 0))) for i in range(start,L+1)]), label='QCM sampling with Sobol')\n",
    "plt.plot(x_values, np.array([np.linalg.norm((E - np.mean(S_rqmc[:i], axis= 0))) for i in range(start,L+1)]), label='RQMC sampling with Sobol')\n",
    "plt.plot(x_values, 1/np.sqrt(x_values), label='1/sqrt(n)')\n",
    "plt.plot(x_values, x_values**(-1+eps), label=f'n^(-1+eps) ; eps = {eps}')\n",
    "plt.ylim(bottom=0)\n",
    "\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('||E[X]-mean(X)n||2')\n",
    "plt.title('evolution of M for different I for p fixed')\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
